Othello timing notes:
(Timings from home computer unless otherwise specified)

r2133: 989 +/-  1.0 ms. Added timer code.
  1032 +/-  0.7 ms: solve1() specialized code for 1 empty remaining
  1029 +/-  0.4 ms: as above with net calculation moved after flip calcs, in case the write to RAM is the problem
  1035 +/-  0.4 ms: as above but only one bitCount operation in flip calcs
  1035 +/-  0.6 ms: as above but rejigger solve1 to have only one return statement
    Guess: branch prediction is causing problems; thus it might be faster if I have a solve2() and maybe solve3() because
    it would know which subroutine it's going into.
   984 +/-  0.5 ms: Specialized solve1() and solve2(). Seem to have caught up with unspecialized code.
r2135: 987 +/-  0.2 ms: Somewhat specialized solve3() - just a copy of solveN() that knows its depth.
    Going to leave it in for now just because it will be a pain to redo, but revisit later once other improvements are tried.
    If the specialization ends up being a negligible gain, I'll remove it to reduce code size.
  524 +/-  0.4 ms: Move to corners first.
r2136: Elapsed time =  528 +/- 0.2 ms. 8.48 Mn; 16.1 Mn/s: Move to corners first; Added node counter.
  440 +/- 0.4 ms. 7.04 Mn; 16.0 Mn/s: Check X-squares last.
  443 +/- 0.0 ms. 7.09 Mn; 16.0 Mn/s: Corners/other/C-squares/X-squares
  467 +/- 0.2 ms. 7.41 Mn; 15.9 Mn/s: Corners/C-squares/other/X-squares
  442 +/- 0.2 ms. 7.07 Mn; 16.0 Mn/s: Corners/A3-squares/other/C/X
  437 +/- 0.2 ms. 7.07 Mn; 16.2 Mn/s: Solver.calcFlips initializes flips to east/west flips instead of initialize to 0 and or east/west flips in.
r2137: As above.
  400 +/- 0.2 ms. 7.07 Mn; 17.7 Mn/s: [X1] Replace east/west flip calculations with magics.
  399 +/- 0.2 ms. 7.07 Mn; 17.7 Mn/s: X1 + Reorder magic indices to improve locality  (not keeping)
r2138: X1
r2140: Add vertical kindergarten bitboards. Timing on work computer goes from 549 to 475 ms.
  First implementation of diagonal kindergarten bitboards uses Long.rotateLeft()/Long.rotateRight().
  On the work machine at least, Long.rotateLeft()/Long.rotateRight() is terribly slow. Adding a single
   rotateLeft/rotateRight combination adds 6ns per node.
r2141: changing move gen from flip |= upDown; flip |= leftRight; etc => flip = upDown | leftRight | etc speeds up to
       466ms on work computer
  Comment: timings on work machine make no sense. Example:
       * only calculating UR/DL flips if the square could have one: timing 447 ms (- 19 ms) on work computer
       * only calculating UL/DR flips if the square could have one: timing 546 ms (+ 80 ms) on work computer.
r2142: only calculate UR/DL flips if the square could have one. Need to double check this result on home computer
       because it has more stable timings.
  Comment (@r2141): timings on home machine are much more stable but equally confusing. Base flip calc: 352ms
       * only calculating UR/DL flips if the square could have one: timing 348 ms (- 4 ms)
       * only calculating UL/DR flips if the square could have one: timing 402 ms (+ 50 ms)

---- Timings changed to use all 8 reflections of each test case ---
r2143: timings with only calculating UR/DL flips if the square could have one, on home computer.
  3228 +/- 1.1 ms. 56.6 Mn; 17.5 Mn/s; 57.1 ns/n
  2841 +/- 0.9 ms. 56.6 Mn; 19.9 Mn/s; 50.2 ns/n: always calculate UR/DL flips
 *2823 +/- 0.8 ms. 56.6 Mn; 20.0 Mn/s; 49.9 ns/n: UR/DL before UL/DR
  2811 +/- 1.9 ms. 56.6 Mn; 20.1 Mn/s; 49.7 ns/n:  ditto
  3265 +/- 0.9 ms. 56.6 Mn; 17.3 Mn/s; 57.7 ns/n: UL/DR only if the square could have one.
  3255 +/- 0.9 ms. 56.6 Mn; 17.4 Mn/s; 57.6 ns/n:  ditto
  3263 +/- 0.8 ms. 56.6 Mn; 17.3 Mn/s; 57.7 ns/n:  ditto, with screen in portrait mode
r2144: always calculate UR/DL then UL/DR (*, above)
  2792 +/- 1.3 ms. 48.1 Mn; 17.2 Mn/s; 58.0 ns/n: Fix bug in node count
  2316 +/- 1.2 ms. 38.6 Mn; 16.7 Mn/s; 60.1 ns/n: Parity check at depth >= 6
r2145: Parity check at depth >= 6.
  2394 +/- 0.7 ms. 40.2 Mn; 16.8 Mn/s; 59.5 ns/n: Parity check at depth >= 7
  2180 +/- 1.0 ms. 36.0 Mn; 16.5 Mn/s; 60.6 ns/n: Parity check at depth >= 5
  2212 +/- 1.3 ms. 35.3 Mn; 16.0 Mn/s; 62.7 ns/n: Parity check at depth >= 4
r2146: Parity check at depth >= 5
  2485 +/- 1.7 ms. 48.9 Mn; 19.7 Mn/s; 50.9 ns/n: Remove specialized code for 1,2,3 empties
  2230 +/- 0.5 ms. 36.6 Mn; 16.4 Mn/s; 61.0 ns/n: Move ordering Corners/A3-squares/C/other/X
  2154 +/- 3.2 ms. 35.3 Mn; 16.4 Mn/s; 61.0 ns/n: Move ordering Corners/other/A3/C/X
  2167 +/- 0.7 ms. 35.7 Mn; 16.5 Mn/s; 60.6 ns/n: Move ordering Corners/B3/other/A3/C/X
 *2128 +/- 1.0 ms. 35.0 Mn; 16.4 Mn/s; 60.9 ns/n: Move ordering Corners/other/B3/A3/C/X
  2138 +/- 0.9 ms. 35.0 Mn; 16.4 Mn/s; 61.0 ns/n: Move ordering Corners/other/A3/B3/C/X
r2147: Move ordering Corners/other/B3/A3/C/X
      Node fractions by depth:
       1: 36.1%
       2: 27.4%
       3: 17.3%
       4:  9.9%
       5:  5.2%
       6:  2.4%
       7:  1.1%
       8:  0.41%
       9:  0.16%
      10:  0.046%
      11:  0.014%
      12:  0.0023%
   Experiment setting min parity depth depending on predicted node type; look at node counts for first validation.
   Original has ALL depth / PV & CUT depth = 5/5
    Depth  Mn
    5/5    35.0
    6/5    35.5
    5/6    37.0
    5/4    34.4
    4/5    34.9
r2153: Work computer 2894 +/- 20.2 ms. 35.0 Mn; 12.1 Mn/s; 82.8 ns/n
  2744W +/- 1.5 ms. 35.0 Mn; 12.7 Mn/s; 78.5 ns/n: KindergartenULDR
r2154: KindergartenULDR
  2681W +/- 6.3 ms. 35.0 Mn; 13.0 Mn/s; 76.7 ns/n: include FlipperULDR in Square to avoid array lookup.
  2570W +/- 12.5 ms. 35.0 Mn; 13.6 Mn/s; 73.5 ns/n: also include FlipperURDL in Square.
r2155: FlipperURDL and ULDR in square
r2159: Move sorter. 1212W +/- 1.9 ms. 15.5 Mn; 12.8 Mn/s; 77.9 ns/n
r2160: Solver tuner. I need to run this on a computer with much more stable timings than the work machine.
  1149W +/- 0.9 ms. 14.8 Mn; 12.8 Mn/s; 77.9 ns/n: sort fixed move order before parity at high depths.
r2161: Move sorting enemy mobility / fixed square order / parity
  average time of 1166W, 15.3 Mn: in solveParity, check parity moves + all corners in first pass
  average time of 1160W, 13.3 Mn: for PV and cut nodes, drop MIN_SORT_DEPTH by 1
  1121W +/- 1.2 ms. 13.3 Mn; 11.9 Mn/s; 84.0 ns/n: for PV and cut nodes, drop MIN_SORT_DEPTH by 1 and reuse mobilities
r2171: with transposition table.
  744 [ 743- 744] ms. 10.3 Mn; 13.9 Mn/s; 72.1 ns/n: r2171
  switching return value to long in FlipperULDR/FlipperURDL.bbIndex did not help, probably slightly slower.
  749 [ 748- 749] ms. 10.3 Mn; 13.8 Mn/s; 72.6 ns/n: Always calculate mobilities to send into moverResultWithParity
      (so that, after a pass, we can check only the legal moves rather than all empties).

:::::: Timings on work computer from here ::::::
r2172 timing on work computer: run timings 3 times to see variation.
   1016 [1011-1030] ms. 10.3 Mn; 10.1 Mn/s; 98.8 ns/n
    999 [ 998-1001] ms. 10.3 Mn; 10.3 Mn/s; 97.4 ns/n
   1000 [ 994-1005] ms. 10.3 Mn; 10.3 Mn/s; 96.7 ns/n
   hash statistics:
    5,265,568 finds and 4,978,224 stores. 105,696 / 169,656 / 11,992 alpha/beta/pv cuts. 56,888 useless finds.

   Using partial hash hits:
     994 [ 989-1000] ms. 10.3 Mn; 10.3 Mn/s; 96.7 ns/n
    1006 [1005-1008] ms. 10.3 Mn; 10.2 Mn/s; 97.8 ns/n
     984 [ 980- 987] ms. 10.3 Mn; 10.5 Mn/s; 95.6 ns/n
   hash statistics:
    5,262,136 finds and 4,977,600 stores. 105,688 / 167,776 / 11,072 alpha/beta/pv cuts. 56,880 useless finds.

    Keeping it. Although it's not a huge gain.
r2173: use partial hash info
    1022, 1015, 1007: create and return a MoveResult object in moverResultWithSorting
    1016, 992, 979: Use an object pool for MoveResults

    Try using 16 iterations per round for timing. Timings are currently tossing the lowest and highest 1/4 of scores and
    reporting the lowest and highest remaining values Q1 and Q3.
    Fun fact: If two sets A and B of 16 timings are selected from the same distribution, the probability that A.Q1 > B.Q3
    is 0.60%. For two sets of 8 timings, it is 6.60%.
    Let's test whether this happens often when we run multiple times with sets of 16:
    1000 [ 986-1010]
     986 [ 983- 987]
     988 [ 980- 993]
     981 [ 970- 992]
     987 [ 983- 991]
    I guess not.

r2176: increased reporting
  Store best move in hash table and use it to inform subsequent searches:
    989 [ 974-1006] ms. 10.28 Mn; 10.4 Mn/s; 96.4 ns/n: Store best move in hash table and use it in subsequent rounds.
    10,522,992 finds and 9,954,880 stores. 211,328 / 334,640 / 22,144 alpha/beta/pv cuts. 113,760 useless finds. 62,848 hash move uses.
  This does not change the node count even in the 4th decimal place, and doesn't change the timing, so removing all the extra code.

  Killer moves: first pass is simply a single square killers[nEmpty], set whenever there's a score above alpha.
  Node count drops to 10.25Mn, a very small decrease.
  Update killers only if bestMoveSq > 0: 10.27Mn.
r2182: tuned node ordering. Node count down to 10.02Mn.
  Killer responses: dropped node count to 9.972Mn
  Killer response, updating only if bestMoveSq > 0 : 9.864Mn.
  Typical 1007 [1001-1015] ms. 9.897 Mn; 9.76 Mn/s; 102 ns/n: Eliminate killer moves, use only killer responses
  While the node count is slightly lower, the time has not decreased and this adds junk to the code. So, eliminating killer
  responses.
r2184: eliminate killers and killer responses
   1001 [ 992-1011] ms. 10.33 Mn; 10.3 Mn/s; 96.9 ns/n: Eliminate parity from MoveSorter
    984 [ 980- 996] ms. 10.03 Mn; 10.2 Mn/s; 98.5 ns/n: Put parity back in. Eliminate PARITY_WEIGHT since it's always 0.
    991 [ 988- 997] ms. 10.03 Mn; 10.1 Mn/s; 98.8 ns/n: Make FIXED_ORDERING_WEIGHT and MOBILITY_WEIGHT final
   1003 [1002-1004] ms. 10.03 Mn; 9.99 Mn/s; 100 ns/n: Eliminate FIXED_ORDERING_WEIGHT since it's 0.
   Having constants at 0 doesn't seem to hurt, so keep them in so can performance tune in the future.
r2185: Make constants constant
  1025 [1024-1025] ms. 9.959 Mn; 9.74 Mn/s; 103 ns/n: Use stable disk approximation (corners + adjacent c-squares) in move sort.
    Not going to use this, since it's slower.
 *975 [ 972- 976] ms. 9.727 Mn; 9.96 Mn/s; 100 ns/n: Use ETC at depth >= 7
  989 [ 988- 990] ms. 9.856 Mn; 9.96 Mn/s; 100 ns/n: Use ETC at depth >= 8
r2186: Add ETC
  908 [ 904- 911] ms. 8.496 Mn; 9.36 Mn/s; 107 ns/n: Negascout
 *886 [ 882- 887] ms. 8.398 Mn; 9.49 Mn/s; 105 ns/n: Negascout at depth >= 10
r2187: Add Negascout
  Note: Found ntest node counts for these problems. Ntest uses ~2.5x as many nodes to solve them. On the other hand
    ntest's nodes are much faster: 13.7 MN/s on the work machine with a full 22-ply solve - ntest reports 7.6% of those
    nodes have a call to the full evaluation function and are therefore not comparable to what we're doing here.

  Search statistics with this revision:
  Node fractions by depth:
   1: 33.7%
   2: 25.7%
   3: 16.9%
   4: 10.1%
   5:  6.0%
   6:  3.7%
   7:  2.1%
   8:  1.1%
   9:  0.51%
  10:  0.18%
  11:  0.063%
  12:  0.0095%

  Predicted node type distribution:
  [ 5] ALL 36%, PV  0%, CUT 64%
  [ 6] ALL 37%, PV  0%, CUT 63%
  [ 7] ALL 30%, PV  0%, CUT 70%
  [ 8] ALL 34%, PV  1%, CUT 65%
  [ 9] ALL 22%, PV  2%, CUT 76%
  [10] ALL 29%, PV  5%, CUT 65%
  [11] ALL  0%, PV 15%, CUT 85%
  [12] ALL  0%, PV 100%, CUT  0%

  31,971,808 finds and 9,365,136 stores. 290,768 / 723,472 / 2,288 alpha/beta/pv cuts. 748,224 useless finds.

  Typical  906 [ 905- 908] ms. 8.38 Mn; 9.28 Mn/s; 108 ns/n: Move ordering: 13 point bonus for X-square next to occupied corner.
:::::: Timings on home computer from here
  666 [ 663- 669] ms. 8.40 Mn; 12.6 Mn/s; 79.4 ns/n: Standard
  998 [ 994-1001] ms. 8.40 Mn; 8.41 Mn/s; 119 ns/n: Flips using Hyperbola Quintessence
  Having timed rotate (8 clock cycles) and now seeing the timing of reverse, it appears the JVM is not using intrinsics
  for many Long functions.
  Home computer is using jdk1.7.0_04. Should update (latest is 1.7.0_45) and see if problem persists.

 Testing whether popcnt is inlined. With -server -XX:-UsePopCountInstruction
  707 [ 704- 709] ms. 8.40 Mn; 11.9 Mn/s; 84.2 ns/n
  704 [ 703- 705] ms. 8.40 Mn; 11.9 Mn/s; 83.9 ns/n
 With  -server -XX:+UsePopCountInstruction
  669 [ 668- 669] ms. 8.40 Mn; 12.6 Mn/s; 79.6 ns/n
  670 [ 665- 674] ms. 8.40 Mn; 12.5 Mn/s; 79.8 ns/n
 Based on these timings, popcnt makes a difference and is enabled by default.

 :::::: Timings on work computer
   This uses slightly different move sorting than the home computer, so the node count is slightly different.
   894 [ 878- 904] ms. 8.35 Mn; 9.34 Mn/s; 107 ns/n: [X1]replace jvm 1.7.0_04 with 1.7.0_45
  New JVM doesn't make a difference, keeping it anyway.
  1371 [1370-1372] ms. 8.35 Mn; 6.10 Mn/s; 164 ns/n: use hyperbolic quintessence
   898 [ 892- 902] ms. 8.35 Mn; 9.29 Mn/s; 108 ns/n: back to [X1].
   938 [ 929- 942] ms. 8.35 Mn; 8.90 Mn/s; 112 ns/n: use o-2r trick in calcMobility.
   Won't use o-2r trick.
  903 [ 897- 907] ms. 8.27 Mn; 9.16 Mn/s; 109 ns/n: MoveSorter scores X-squares and C-squares higher if next to occupied corners.
  905 [ 897- 907] ms. 8.27 Mn; 9.16 Mn/s; 109 ns/n: Ditto
  919 [ 914- 922] ms. 8.27 Mn; 9.00 Mn/s; 111 ns/n: Slightly different implementation of above
  881 [ 870- 894] ms. 8.27 Mn; 9.34 Mn/s; 107 ns/n: Implementation of above using masks instead of ifs
  892 [ 889- 894] ms. 8.27 Mn; 9.22 Mn/s; 108 ns/n: Ditto
  908 [ 892- 914] ms. 8.27 Mn; 9.14 Mn/s; 109 ns/n: Ditto
   Mask trick seems to make no difference.
   MoveSorter knowing about x- and c-squares next to occupied corners drops nodes from 8.40 to 8.27 but
   doesn't speed it up at all. Removing the code for now.

  Using a different PARITY_WEIGHT for odd and even plies: doesn't reduce the number of nodes.

  Going to have to go deeper.
  Move ordering idea based on time/success chance tradeoff:
  let k = eval - (beta+4). If k >= 0 sort based on enemy mobility ("n"), otherwise based on a combination of mobility and eval.
  Specifically, sort score = -ln(n) + k*constant * (k<0 ? 1 : 0.001).  Tune constant by depth I think.

Coefficient calculation
-----------------------
  Trying to figure out the best way to generate coefficients.
  Currently using linear regression on score of playouts. Playout uses Eval4/A (current best bot). Playout positions
  are random positions with 9 empties.
  On top of that, choose 10% of those playout positions and do another playout from that position, adding only the first
  two positions. This is vital for evaluation functions with more than about 10 coefficients, otherwise the results are
  horrible.

  Eval4 (corner mobility and access).
    Coefficients A generated from self-play of Bobby bot with no random subpositions.
  Eval5 (corner mobility and access, # mobilities, # disks)
    All coefficients generated from self-play of Eval4/A, with random subpositions except for A.
    Coefficients A: no random subpositions, penalty = 10k
    Coefficients B: penalty = 10k
    Coefficients C: penalty = 1k
    Coefficients D: penalty = 100
    Coefficients E: penalty = 10

  Tournament results (just top 4 players)
     +2.4  eval5/D
     +1.8  eval5/E
     +0.1  eval5/C
     -4.3  eval4/A

  Tournament results (bottom 4 players)
      +15.7  eval4/A
      +14.5  eval5/C
       +4.2  eval5/B
      -34.4  eval5/A

  From the difference between eval5/A and eval5/B it's clear the random subpositions help a lot.
  Trying subpositions with eval4. With penalty 100, this is coefficient set B.

  Tournament results:
      +10.4  eval4/B
       -0.3  eval5/D
       -1.0  eval5/E
       -2.5  eval5/C
       -6.6  eval4/A

  If random subpositions are good, are more better? Trying new evals with 20% random subpositions instead of 10%.
  These are eval4/C and eval5/F, both with penalty 100.

  Tournament results:
     +10.7  eval4/C
      +2.0  eval4/B
      -5.0  eval5/F
      -7.7  eval5/D

Now 100% random subpositions. 4-D and 5-H.

    Tournament results:
    +12.0  eval4-D-1
     +6.3  eval4-C-1
     -9.1  eval5-H-1
     -9.2  eval5-F-1

More seems better, at least for eval4-D.

### X-square coefficients

Eval4 coefficients are positive for x-squares at depths < approximately 22. This is stupid.

Tried a tournament with "Charlie", a coefficient set for eval4 that has negative values for x-squares (in fact, I just copied eval4-D's coefficients from 30 empties to all empties).

Tournament results:
+20.1  eval4-Charlie-1
 +5.9  eval4-D-1
 +1.6  eval4-C-1
-13.7  eval5-H-1
-13.9  eval5-F-1

Clearly there is a problem here.

### search depth

Played Charlie:depth 1 vs Charlie:depth 2. average result = -21.0 +/- 0.14. T ~  -152.

4D:1 vs 4D:2. average result -4.93 +/- 0.14. T ~ -36.4

4D:2 can more effectively take x-squares, which is hurting its performance (I think).

### Non-random positions

Are the non-random positions hurting? Try generating positions without the main line: 4-E and 5-I.
Figuring out the coefficients is a lot faster with the non-random positions; perhaps the many copies of each game position cause a lot of off-diagonal entries in the conjugate gradient matrix?

4E still wants to take x-squares around 20 empty.

    Tournament results:
    +19.0  eval4-Charlie-1
     +4.2  eval4-E-1
     +3.4  eval4-D-1
    -11.2  eval5-I-1
    -15.5  eval5-H-1

So removing the non-random positions helps! We'll do that.

### Bad Playouts?

Possibly part of the x-square problem is that Eval4-A, which generates the playouts, is messed up. Try again using Charlie to generate the playouts.

New players: 5J, 4F.

    Tournament results:
    +11.6  eval4-F-1
     +8.8  eval5-J-1
     +5.8  eval4-Charlie-1
     -5.3  eval4-E-1
    -21.0  eval5-I-1

* Using better playouts improved the results by an average of 23 disks.

Clearly the quality of the playouts has a massive impact on the evaluation function. Obviously improving the evaluation
function is one way to improve the playouts, but another is to increase the search depth. Let's see how much better these
new players are at increased search depth:

    Tournament results:
    +26.7  eval5-J-2
     +6.8  eval4-F-2
     +2.6  eval4-Charlie-2
     -8.8  eval5-J-1
     -9.2  eval4-F-1
    -18.1  eval4-Charlie-1

* Going to 2 ply helps by an average of 24 disks. This is much larger than the difference in the evals.
* At 2 ply, eval5 is better than eval4. eval5:1 (1 ply) did much better against the 2-ply bots than eval4:1. Probably the mobility term?

Since I'm going home, I will generate pvs using playouts from 5J:2 to see if that will generate even better coefficients.
The new coefficient sets will be 4G and 5K.

    Tournament results:
    +18.6  eval5-K-2
    +13.7  eval5-J-2
     -8.2  eval4-F-2
     -9.9  eval4-G-2
    -14.2  eval4-Charlie-2

The new coefficients helped by an average of 3 disks - not huge but better than a stick in the eye.

### Potential Mobility ###

One obvious weakness of the bots play is potential mobility - they are perfectly happy to have lots of boundary disks.

New evaluator 6 uses pot mob as a pattern. The coefficients on it are very large even in the endgame - perhaps this
will help our endgame play.

    Tournament results:
    +43.5  6A:2
    +12.6  5K:2
    -12.0  4G:2
    -15.3  6A:1
    -28.8  5K:1

Obviously this is a keeper.

Move Sorting
============

Trying potential mobility in Move Sorting.

### Without potential mobility ###

    914 [ 913- 917] ms. 8.40 Mn; 9.18 Mn/s; 109 ns/n

    Node fractions by depth:
     1: 33.7%
     2: 25.7%
     3: 16.9%
     4: 10.1%
     5:  6.0%
     6:  3.7%       First cut: 89%. Wasted: 0.15
     7:  2.1%       First cut: 85%. Wasted: 0.22
     8:  1.1%       First cut: 83%. Wasted: 0.26
     9:  0.51%      First cut: 80%. Wasted: 0.31
    10:  0.18%      First cut: 78%. Wasted: 0.36
    11:  0.063%     First cut: 78%. Wasted: 0.33
    12:  0.0095%

### With potential mobility ###

    887 [ 876- 894] ms. 7.99 Mn; 9.02 Mn/s; 111 ns/n

    Node fractions by depth:
     1: 33.6%
     2: 25.7%
     3: 16.8%
     4: 10.1%
     5:  5.9%
     6:  3.7%       First cut: 90%. Wasted: 0.14
     7:  2.1%       First cut: 86%. Wasted: 0.20
     8:  1.1%       First cut: 85%. Wasted: 0.23
     9:  0.53%      First cut: 83%. Wasted: 0.28
    10:  0.19%      First cut: 80%. Wasted: 0.32
    11:  0.067%     First cut: 81%. Wasted: 0.28
    12:  0.010%

    Predicted node type distribution:
    [ 5] ALL 37%, PV  0%, CUT 63%
    [ 6] ALL 36%, PV  0%, CUT 64%
    [ 7] ALL 31%, PV  0%, CUT 68%
    [ 8] ALL 32%, PV  1%, CUT 67%
    [ 9] ALL 25%, PV  2%, CUT 73%
    [10] ALL 31%, PV  5%, CUT 64%
    [11] ALL 11%, PV 15%, CUT 74%
    [12] ALL  0%, PV 100%, CUT  0%

After slightly tuning move ordering weights using SolverTuner, node count goes down to 7.97Mn.

With all move ordering weights non-final
    896 [ 893- 899] ms. 7.97 Mn; 8.88 Mn/s; 113 ns/n
    893 [ 891- 895] ms. 7.97 Mn; 8.94 Mn/s; 112 ns/n

With all move-ordering weights final:
    895 [ 893- 899] ms. 7.97 Mn; 8.90 Mn/s; 112 ns/n

final and subtracting 5 makes some weights 0, so the compiler can eliminate the shifts:
    887 [ 881- 889] ms. 8.04 Mn; 9.08 Mn/s; 110 ns/n

These seem to bounce around a lot, so not sure how much all this is helping.

### Results from version checked in ###

    Typical  873 [ 862- 878] ms. 7.97 Mn; 9.13 Mn/s; 110 ns/n

    Node fractions by depth:
     1: 33.6%
     2: 25.7%
     3: 16.9%
     4: 10.1%
     5:  6.0%
     6:  3.7%       First cut: 89%. Wasted: 0.14
     7:  2.1%       First cut: 85%. Wasted: 0.21
     8:  1.1%       First cut: 84%. Wasted: 0.24
     9:  0.53%      First cut: 81%. Wasted: 0.30
    10:  0.19%      First cut: 78%. Wasted: 0.36
    11:  0.067%     First cut: 78%. Wasted: 0.32
    12:  0.010%

    Predicted node type distribution:
    [ 5] ALL 37%, PV  0%, CUT 63%
    [ 6] ALL 36%, PV  0%, CUT 63%
    [ 7] ALL 31%, PV  0%, CUT 69%
    [ 8] ALL 33%, PV  1%, CUT 66%
    [ 9] ALL 24%, PV  2%, CUT 74%
    [10] ALL 32%, PV  5%, CUT 63%
    [11] ALL 10%, PV 15%, CUT 75%
    [12] ALL  0%, PV 100%, CUT  0%

    31,106,608 finds and 9,049,840 stores. 269,440 / 718,992 / 1,664 alpha/beta/pv cuts. 703,504 useless finds.

Eval
====

Try using edge patterns for eval: this is eval 7A. Compare to older non-edge-pattern evals 6A and 5K.

    Tournament results:
    +46.2  7A:2
    +16.5  6A:2
    -13.0  7A:1
    -15.2  5K:2
    -34.5  6A:1


Found a bug in evalPlayer (evaluated position using the mover's moves for both moverMoves and enemyMoves).
All previous tournament results are thus suspect as are the values from playouts.

Reran the previous tournament:
    +40.0  7A:2
    +20.6  6A:2
     +4.2  5K:2
    -20.9  7A:1
    -43.9  6A:1

Midgame Speed
=============
It's getting painfully slow even at 2 ply.

Check node count of a SelfPlaySet, 7A:2 vs 7A:2
    110,538,379 position evaluations performed.

Try corners first, x-squares last:
    106,405,074 position evaluations performed.

Coefficient calculation
=======================

7A:2 (no bug) surely produces much better playouts than 5J:2 (with bug). Used 7A:2 as playout player and
reran coefficients for 6B and 7B. [Coefficient index frequency distribution][frequency.txt]

    Tournament results:
    +30.0  7B:2
     +1.2  6B:2
     -5.4  7A:2
    -25.8  6A:2

Play vs NTest
=============

Set up to play vs Ntest. This is slow because of inter-process communication, so I cut off before the end, but 7A loses quite badly.
    7A:2 vs NTest:2  after 15,000 matches, average result = -59.2 +/- 0.24. T ~  -248
    7A:2 vs NTest:1  after 15,000 matches, average result = -39.7 +/- 0.27. T ~  -150

Whoops, just realized 7B is the current version, and much better.
    7B:2 vs NTest:1  after 10,000 matches, average result = -17.0 +/- 0.34. T ~ -50.3

Coefficients 8A now available:
    8A:2 vs NTest:1  after 15,000 matches, average result = -11.2 +/- 0.27. T ~ -41.2
    8A:2 vs NTest:2  after 10,000 matches, average result = -33.7 +/- 0.31. T ~  -110

Still have a ways to go.

Coefficient calculation
=======================

Add PotMobs2 as an evaluation term. Coefficients are fairly small compared to PotMobs, range from lowest coefficient to highest within MoverPotMobs and also EnemyPotMobs is typically ~7. This is surely correlated with PotMobs, too, so I wasn't expecting too much improvement.

    7B:2 vs 8A:2: average result = -5.4

While small, I'll keep it. We're not doing performance tuning yet.

Add all rows as evaluation terms instead of just edges.

    9A:2 vs 8A:2: average result = 7.9
    9A:2 vs NTest:1: average result = -4.7

Found a bug if there was a pass in midgame search. Fixed!

    9A:2 vs NTest:1: average result = -4.2

Added eval 'a' which uses diagonal lines also. Also recalculated coefficients 9 using 9A instead of older 7A;
this is coefficient set 9B.

    a1:2 vs NTest:1: average result = 6.3

    Tournament results:
    +11.3  a1:2
     +2.3  9B:2
    -13.6  9A:2

Added eval 'b' using 3x3 corner blocks.

    b1:2 vs NTest:2: average result = -12.7

    Tournament results:
    +11.3  b1:2
     -1.3  a1:2
    -10.0  9b:2

Deep Solver
===========
[86d7a78] Starting statistics for DeepSolverTimer at depth 20:
    6,787 ms elapsed; 70,092,939 total nodes

    Node fractions by depth:
     1: 31.8%
     2: 24.0%
     3: 16.8%
     4:  9.9%
     5:  6.6%
     6:  4.2%       First cut: 93%. Wasted: 0.10
     7:  2.9%       First cut: 93%. Wasted: 0.10
     8:  1.6%       First cut: 91%. Wasted: 0.13
     9:  1.1%       First cut: 93%. Wasted: 0.10
    10:  0.49%      First cut: 89%. Wasted: 0.16
    11:  0.31%      First cut: 92%. Wasted: 0.11
    12:  0.12%      First cut: 88%. Wasted: 0.19
    13:  0.073%     First cut: 91%. Wasted: 0.13
    14:  0.024%     First cut: 86%. Wasted: 0.23
    15:  0.013%     First cut: 89%. Wasted: 0.16
    16:  0.0036%    First cut: 83%. Wasted: 0.31
    17:  0.0017%    First cut: 87%. Wasted: 0.20
    18:  0.00039%   First cut: 78%. Wasted: 0.40
    19:  0.00015%   First cut: 82%. Wasted: 0.35
    20:  1.4e-05%

    Predicted node type distribution:
    [ 5] ALL 35%, PV  0%, CUT 65%
    [ 6] ALL 47%, PV  0%, CUT 53%
    [ 7] ALL 29%, PV  0%, CUT 71%
    [ 8] ALL 48%, PV  0%, CUT 52%
    [ 9] ALL 24%, PV  0%, CUT 76%
    [10] ALL 49%, PV  0%, CUT 51%
    [11] ALL 20%, PV  0%, CUT 80%
    [12] ALL 48%, PV  0%, CUT 52%
    [13] ALL 18%, PV  0%, CUT 82%
    [14] ALL 46%, PV  0%, CUT 54%
    [15] ALL 16%, PV  0%, CUT 84%
    [16] ALL 42%, PV  0%, CUT 57%
    [17] ALL 15%, PV  1%, CUT 84%
    [18] ALL 38%, PV  4%, CUT 59%
    [19] ALL  5%, PV 10%, CUT 86%
    [20] ALL  0%, PV 100%, CUT  0%

    33,688,406 finds and 8,614,016 stores. 312,809 / 347,649 / 21 alpha/beta/pv cuts. 21,595 useless finds.

Hash Table
----------
6510 ms elapsed: Separate hash-tables by depth (64 hash buckets per depth)

Deep Move Sorting
-----------------
9,183 ms elapsed; 75,809,707 total nodes: Eval-based move sort at depth >= 12, with no FF adjustment
5,252 ms elapsed; 43,713,320 total nodesL Eval -based move sort at depth >= 12, with DEEP_MOBILITY_WEIGHT = 4.

Speed up eval
-------------
4,969 ms elapsed; 43,713,320 total nodes

Running SolverTimer (so HotSpot warms up):
Typical 4245 [4239-4253] ms. 43.7 Mn; 10.3 Mn/s; 97.2 ns/n

Hash Table
----------
Different hash size per depth. Checking total node count. DeepSolverTest from 20 empty.
    log buckets   result
             15   5,480 ms elapsed; 34,322,025 total nodes
             12   4,296 ms elapsed; 35,283,870 total nodes
             10   4,348 ms elapsed; 36,750,608 total nodes
              8   4,541 ms elapsed; 39,237,209 total nodes
              5   5,319 ms elapsed; 48,065,104 total nodes

          10-12   4,237 ms elapsed; 35,652,697 total nodes
          10-15   5,299 ms elapsed; 35,035,733 total nodes

Presumably the reason 15 is slower is due to hitting RAM instead of L3 cache. Thus, keeping log buckets at 10
(even though 12 is faster) on the assumption that, running multiple cores simultaneously will use even more cache
and thus will be optimal at 10.

Better idea: use a small hash at low empties and a larger hash at higher empties; thus the small hash will fit in cache
while the larger hash will hold more valuable information where it's worth it to go out to RAM.

SolverTimer
===========
Rechecking SolverTimer in light of the previous section. At depth12, a lot of its time is spent in HashTable.clear()
making sure we don't cheat on the benchmarks. Changed it so HashTable.clear() only clears entries that will used by
the test, so it only clears the section between 6 empties and the number of empties in the position.