Othello timing notes:
(Timings from home computer unless otherwise specified)

r2133: 989 +/-  1.0 ms. Added timer code.
  1032 +/-  0.7 ms: solve1() specialized code for 1 empty remaining
  1029 +/-  0.4 ms: as above with net calculation moved after flip calcs, in case the write to RAM is the problem
  1035 +/-  0.4 ms: as above but only one bitCount operation in flip calcs
  1035 +/-  0.6 ms: as above but rejigger solve1 to have only one return statement
    Guess: branch prediction is causing problems; thus it might be faster if I have a solve2() and maybe solve3() because
    it would know which subroutine it's going into.
   984 +/-  0.5 ms: Specialized solve1() and solve2(). Seem to have caught up with unspecialized code.
r2135: 987 +/-  0.2 ms: Somewhat specialized solve3() - just a copy of solveN() that knows its depth.
    Going to leave it in for now just because it will be a pain to redo, but revisit later once other improvements are tried.
    If the specialization ends up being a negligible gain, I'll remove it to reduce code size.
  524 +/-  0.4 ms: Move to corners first.
r2136: Elapsed time =  528 +/- 0.2 ms. 8.48 Mn; 16.1 Mn/s: Move to corners first; Added node counter.
  440 +/- 0.4 ms. 7.04 Mn; 16.0 Mn/s: Check X-squares last.
  443 +/- 0.0 ms. 7.09 Mn; 16.0 Mn/s: Corners/other/C-squares/X-squares
  467 +/- 0.2 ms. 7.41 Mn; 15.9 Mn/s: Corners/C-squares/other/X-squares
  442 +/- 0.2 ms. 7.07 Mn; 16.0 Mn/s: Corners/A3-squares/other/C/X
  437 +/- 0.2 ms. 7.07 Mn; 16.2 Mn/s: Solver.calcFlips initializes flips to east/west flips instead of initialize to 0 and or east/west flips in.
r2137: As above.
  400 +/- 0.2 ms. 7.07 Mn; 17.7 Mn/s: [X1] Replace east/west flip calculations with magics.
  399 +/- 0.2 ms. 7.07 Mn; 17.7 Mn/s: X1 + Reorder magic indices to improve locality  (not keeping)
r2138: X1
r2140: Add vertical kindergarten bitboards. Timing on work computer goes from 549 to 475 ms.
  First implementation of diagonal kindergarten bitboards uses Long.rotateLeft()/Long.rotateRight().
  On the work machine at least, Long.rotateLeft()/Long.rotateRight() is terribly slow. Adding a single
   rotateLeft/rotateRight combination adds 6ns per node.
r2141: changing move gen from flip |= upDown; flip |= leftRight; etc => flip = upDown | leftRight | etc speeds up to
       466ms on work computer
  Comment: timings on work machine make no sense. Example:
       * only calculating UR/DL flips if the square could have one: timing 447 ms (- 19 ms) on work computer
       * only calculating UL/DR flips if the square could have one: timing 546 ms (+ 80 ms) on work computer.
r2142: only calculate UR/DL flips if the square could have one. Need to double check this result on home computer
       because it has more stable timings.
  Comment (@r2141): timings on home machine are much more stable but equally confusing. Base flip calc: 352ms
       * only calculating UR/DL flips if the square could have one: timing 348 ms (- 4 ms)
       * only calculating UL/DR flips if the square could have one: timing 402 ms (+ 50 ms)

---- Timings changed to use all 8 reflections of each test case ---
r2143: timings with only calculating UR/DL flips if the square could have one, on home computer.
  3228 +/- 1.1 ms. 56.6 Mn; 17.5 Mn/s; 57.1 ns/n
  2841 +/- 0.9 ms. 56.6 Mn; 19.9 Mn/s; 50.2 ns/n: always calculate UR/DL flips
 *2823 +/- 0.8 ms. 56.6 Mn; 20.0 Mn/s; 49.9 ns/n: UR/DL before UL/DR
  2811 +/- 1.9 ms. 56.6 Mn; 20.1 Mn/s; 49.7 ns/n:  ditto
  3265 +/- 0.9 ms. 56.6 Mn; 17.3 Mn/s; 57.7 ns/n: UL/DR only if the square could have one.
  3255 +/- 0.9 ms. 56.6 Mn; 17.4 Mn/s; 57.6 ns/n:  ditto
  3263 +/- 0.8 ms. 56.6 Mn; 17.3 Mn/s; 57.7 ns/n:  ditto, with screen in portrait mode
r2144: always calculate UR/DL then UL/DR (*, above)
  2792 +/- 1.3 ms. 48.1 Mn; 17.2 Mn/s; 58.0 ns/n: Fix bug in node count
  2316 +/- 1.2 ms. 38.6 Mn; 16.7 Mn/s; 60.1 ns/n: Parity check at depth >= 6
r2145: Parity check at depth >= 6.
  2394 +/- 0.7 ms. 40.2 Mn; 16.8 Mn/s; 59.5 ns/n: Parity check at depth >= 7
  2180 +/- 1.0 ms. 36.0 Mn; 16.5 Mn/s; 60.6 ns/n: Parity check at depth >= 5
  2212 +/- 1.3 ms. 35.3 Mn; 16.0 Mn/s; 62.7 ns/n: Parity check at depth >= 4
r2146: Parity check at depth >= 5
  2485 +/- 1.7 ms. 48.9 Mn; 19.7 Mn/s; 50.9 ns/n: Remove specialized code for 1,2,3 empties
  2230 +/- 0.5 ms. 36.6 Mn; 16.4 Mn/s; 61.0 ns/n: Move ordering Corners/A3-squares/C/other/X
  2154 +/- 3.2 ms. 35.3 Mn; 16.4 Mn/s; 61.0 ns/n: Move ordering Corners/other/A3/C/X
  2167 +/- 0.7 ms. 35.7 Mn; 16.5 Mn/s; 60.6 ns/n: Move ordering Corners/B3/other/A3/C/X
 *2128 +/- 1.0 ms. 35.0 Mn; 16.4 Mn/s; 60.9 ns/n: Move ordering Corners/other/B3/A3/C/X
  2138 +/- 0.9 ms. 35.0 Mn; 16.4 Mn/s; 61.0 ns/n: Move ordering Corners/other/A3/B3/C/X
r2147: Move ordering Corners/other/B3/A3/C/X
      Node fractions by depth:
       1: 36.1%
       2: 27.4%
       3: 17.3%
       4:  9.9%
       5:  5.2%
       6:  2.4%
       7:  1.1%
       8:  0.41%
       9:  0.16%
      10:  0.046%
      11:  0.014%
      12:  0.0023%
   Experiment setting min parity depth depending on predicted node type; look at node counts for first validation.
   Original has ALL depth / PV & CUT depth = 5/5
    Depth  Mn
    5/5    35.0
    6/5    35.5
    5/6    37.0
    5/4    34.4
    4/5    34.9
r2153: Work computer 2894 +/- 20.2 ms. 35.0 Mn; 12.1 Mn/s; 82.8 ns/n
  2744W +/- 1.5 ms. 35.0 Mn; 12.7 Mn/s; 78.5 ns/n: KindergartenULDR
r2154: KindergartenULDR
  2681W +/- 6.3 ms. 35.0 Mn; 13.0 Mn/s; 76.7 ns/n: include FlipperULDR in Square to avoid array lookup.
  2570W +/- 12.5 ms. 35.0 Mn; 13.6 Mn/s; 73.5 ns/n: also include FlipperURDL in Square.
r2155: FlipperURDL and ULDR in square
r2159: Move sorter. 1212W +/- 1.9 ms. 15.5 Mn; 12.8 Mn/s; 77.9 ns/n
r2160: Solver tuner. I need to run this on a computer with much more stable timings than the work machine.
  1149W +/- 0.9 ms. 14.8 Mn; 12.8 Mn/s; 77.9 ns/n: sort fixed move order before parity at high depths.
r2161: Move sorting enemy mobility / fixed square order / parity
  average time of 1166W, 15.3 Mn: in solveParity, check parity moves + all corners in first pass
  average time of 1160W, 13.3 Mn: for PV and cut nodes, drop MIN_SORT_DEPTH by 1
  1121W +/- 1.2 ms. 13.3 Mn; 11.9 Mn/s; 84.0 ns/n: for PV and cut nodes, drop MIN_SORT_DEPTH by 1 and reuse mobilities
r2171: with transposition table.
  744 [ 743- 744] ms. 10.3 Mn; 13.9 Mn/s; 72.1 ns/n: r2171
  switching return value to long in FlipperULDR/FlipperURDL.bbIndex did not help, probably slightly slower.
  749 [ 748- 749] ms. 10.3 Mn; 13.8 Mn/s; 72.6 ns/n: Always calculate mobilities to send into moverResultWithParity
      (so that, after a pass, we can check only the legal moves rather than all empties).

:::::: Timings on work computer from here ::::::
r2172 timing on work computer: run timings 3 times to see variation.
   1016 [1011-1030] ms. 10.3 Mn; 10.1 Mn/s; 98.8 ns/n
    999 [ 998-1001] ms. 10.3 Mn; 10.3 Mn/s; 97.4 ns/n
   1000 [ 994-1005] ms. 10.3 Mn; 10.3 Mn/s; 96.7 ns/n
   hash statistics:
    5,265,568 finds and 4,978,224 stores. 105,696 / 169,656 / 11,992 alpha/beta/pv cuts. 56,888 useless finds.

   Using partial hash hits:
     994 [ 989-1000] ms. 10.3 Mn; 10.3 Mn/s; 96.7 ns/n
    1006 [1005-1008] ms. 10.3 Mn; 10.2 Mn/s; 97.8 ns/n
     984 [ 980- 987] ms. 10.3 Mn; 10.5 Mn/s; 95.6 ns/n
   hash statistics:
    5,262,136 finds and 4,977,600 stores. 105,688 / 167,776 / 11,072 alpha/beta/pv cuts. 56,880 useless finds.

    Keeping it. Although it's not a huge gain.
r2173: use partial hash info
    1022, 1015, 1007: create and return a MoveResult object in moverResultWithSorting
    1016, 992, 979: Use an object pool for MoveResults

    Try using 16 iterations per round for timing. Timings are currently tossing the lowest and highest 1/4 of scores and
    reporting the lowest and highest remaining values Q1 and Q3.
    Fun fact: If two sets A and B of 16 timings are selected from the same distribution, the probability that A.Q1 > B.Q3
    is 0.60%. For two sets of 8 timings, it is 6.60%.
    Let's test whether this happens often when we run multiple times with sets of 16:
    1000 [ 986-1010]
     986 [ 983- 987]
     988 [ 980- 993]
     981 [ 970- 992]
     987 [ 983- 991]
    I guess not.

r2176: increased reporting
  Store best move in hash table and use it to inform subsequent searches:
    989 [ 974-1006] ms. 10.28 Mn; 10.4 Mn/s; 96.4 ns/n: Store best move in hash table and use it in subsequent rounds.
    10,522,992 finds and 9,954,880 stores. 211,328 / 334,640 / 22,144 alpha/beta/pv cuts. 113,760 useless finds. 62,848 hash move uses.
  This does not change the node count even in the 4th decimal place, and doesn't change the timing, so removing all the extra code.

  Killer moves: first pass is simply a single square killers[nEmpty], set whenever there's a score above alpha.
  Node count drops to 10.25Mn, a very small decrease.
  Update killers only if bestMoveSq > 0: 10.27Mn.
r2182: tuned node ordering. Node count down to 10.02Mn.
  Killer responses: dropped node count to 9.972Mn
  Killer response, updating only if bestMoveSq > 0 : 9.864Mn.
  Typical 1007 [1001-1015] ms. 9.897 Mn; 9.76 Mn/s; 102 ns/n: Eliminate killer moves, use only killer responses
  While the node count is slightly lower, the time has not decreased and this adds junk to the code. So, eliminating killer
  responses.
r2184: eliminate killers and killer responses
   1001 [ 992-1011] ms. 10.33 Mn; 10.3 Mn/s; 96.9 ns/n: Eliminate parity from MoveSorter
    984 [ 980- 996] ms. 10.03 Mn; 10.2 Mn/s; 98.5 ns/n: Put parity back in. Eliminate PARITY_WEIGHT since it's always 0.
    991 [ 988- 997] ms. 10.03 Mn; 10.1 Mn/s; 98.8 ns/n: Make FIXED_ORDERING_WEIGHT and MOBILITY_WEIGHT final
   1003 [1002-1004] ms. 10.03 Mn; 9.99 Mn/s; 100 ns/n: Eliminate FIXED_ORDERING_WEIGHT since it's 0.
   Having constants at 0 doesn't seem to hurt, so keep them in so can performance tune in the future.
r2185: Make constants constant
  1025 [1024-1025] ms. 9.959 Mn; 9.74 Mn/s; 103 ns/n: Use stable disk approximation (corners + adjacent c-squares) in move sort.
    Not going to use this, since it's slower.
 *975 [ 972- 976] ms. 9.727 Mn; 9.96 Mn/s; 100 ns/n: Use ETC at depth >= 7
  989 [ 988- 990] ms. 9.856 Mn; 9.96 Mn/s; 100 ns/n: Use ETC at depth >= 8
r2186: Add ETC
  908 [ 904- 911] ms. 8.496 Mn; 9.36 Mn/s; 107 ns/n: Negascout
 *886 [ 882- 887] ms. 8.398 Mn; 9.49 Mn/s; 105 ns/n: Negascout at depth >= 10
r2187: Add Negascout
  Note: Found ntest node counts for these problems. Ntest uses ~2.5x as many nodes to solve them. On the other hand
    ntest's nodes are much faster: 13.7 MN/s on the work machine with a full 22-ply solve - ntest reports 7.6% of those
    nodes have a call to the full evaluation function and are therefore not comparable to what we're doing here.

  Search statistics with this revision:
  Node fractions by depth:
   1: 33.7%
   2: 25.7%
   3: 16.9%
   4: 10.1%
   5:  6.0%
   6:  3.7%
   7:  2.1%
   8:  1.1%
   9:  0.51%
  10:  0.18%
  11:  0.063%
  12:  0.0095%

  Predicted node type distribution:
  [ 5] ALL 36%, PV  0%, CUT 64%
  [ 6] ALL 37%, PV  0%, CUT 63%
  [ 7] ALL 30%, PV  0%, CUT 70%
  [ 8] ALL 34%, PV  1%, CUT 65%
  [ 9] ALL 22%, PV  2%, CUT 76%
  [10] ALL 29%, PV  5%, CUT 65%
  [11] ALL  0%, PV 15%, CUT 85%
  [12] ALL  0%, PV 100%, CUT  0%

  31,971,808 finds and 9,365,136 stores. 290,768 / 723,472 / 2,288 alpha/beta/pv cuts. 748,224 useless finds.

  Typical  906 [ 905- 908] ms. 8.38 Mn; 9.28 Mn/s; 108 ns/n: Move ordering: 13 point bonus for X-square next to occupied corner.
:::::: Timings on home computer from here
  666 [ 663- 669] ms. 8.40 Mn; 12.6 Mn/s; 79.4 ns/n: Standard
  998 [ 994-1001] ms. 8.40 Mn; 8.41 Mn/s; 119 ns/n: Flips using Hyperbola Quintessence
  Having timed rotate (8 clock cycles) and now seeing the timing of reverse, it appears the JVM is not using intrinsics
  for many Long functions.
  Home computer is using jdk1.7.0_04. Should update (latest is 1.7.0_45) and see if problem persists.

 Testing whether popcnt is inlined. With -server -XX:-UsePopCountInstruction
  707 [ 704- 709] ms. 8.40 Mn; 11.9 Mn/s; 84.2 ns/n
  704 [ 703- 705] ms. 8.40 Mn; 11.9 Mn/s; 83.9 ns/n
 With  -server -XX:+UsePopCountInstruction
  669 [ 668- 669] ms. 8.40 Mn; 12.6 Mn/s; 79.6 ns/n
  670 [ 665- 674] ms. 8.40 Mn; 12.5 Mn/s; 79.8 ns/n
 Based on these timings, popcnt makes a difference and is enabled by default.

 :::::: Timings on work computer
   This uses slightly different move sorting than the home computer, so the node count is slightly different.
   894 [ 878- 904] ms. 8.35 Mn; 9.34 Mn/s; 107 ns/n: [X1]replace jvm 1.7.0_04 with 1.7.0_45
  New JVM doesn't make a difference, keeping it anyway.
  1371 [1370-1372] ms. 8.35 Mn; 6.10 Mn/s; 164 ns/n: use hyperbolic quintessence
   898 [ 892- 902] ms. 8.35 Mn; 9.29 Mn/s; 108 ns/n: back to [X1].
   938 [ 929- 942] ms. 8.35 Mn; 8.90 Mn/s; 112 ns/n: use o-2r trick in calcMobility.
   Won't use o-2r trick.
  903 [ 897- 907] ms. 8.27 Mn; 9.16 Mn/s; 109 ns/n: MoveSorter scores X-squares and C-squares higher if next to occupied corners.
  905 [ 897- 907] ms. 8.27 Mn; 9.16 Mn/s; 109 ns/n: Ditto
  919 [ 914- 922] ms. 8.27 Mn; 9.00 Mn/s; 111 ns/n: Slightly different implementation of above
  881 [ 870- 894] ms. 8.27 Mn; 9.34 Mn/s; 107 ns/n: Implementation of above using masks instead of ifs
  892 [ 889- 894] ms. 8.27 Mn; 9.22 Mn/s; 108 ns/n: Ditto
  908 [ 892- 914] ms. 8.27 Mn; 9.14 Mn/s; 109 ns/n: Ditto
   Mask trick seems to make no difference.
   MoveSorter knowing about x- and c-squares next to occupied corners drops nodes from 8.40 to 8.27 but
   doesn't speed it up at all. Removing the code for now.

  Using a different PARITY_WEIGHT for odd and even plies: doesn't reduce the number of nodes.

  Going to have to go deeper.
  Move ordering idea based on time/success chance tradeoff:
  let k = eval - (beta+4). If k >= 0 sort based on enemy mobility ("n"), otherwise based on a combination of mobility and eval.
  Specifically, sort score = -ln(n) + k*constant * (k<0 ? 1 : 0.001).  Tune constant by depth I think.

Coefficient calculation
-----------------------
  Trying to figure out the best way to generate coefficients.
  Currently using linear regression on score of playouts. Playout uses Eval4/A (current best bot). Playout positions
  are random positions with 9 empties.
  On top of that, choose 10% of those playout positions and do another playout from that position, adding only the first
  two positions. This is vital for evaluation functions with more than about 10 coefficients, otherwise the results are
  horrible.

  Eval4 (corner mobility and access).
    Coefficients A generated from self-play of Bobby bot with no random subpositions.
  Eval5 (corner mobility and access, # mobilities, # disks)
    All coefficients generated from self-play of Eval4/A, with random subpositions except for A.
    Coefficients A: no random subpositions, penalty = 10k
    Coefficients B: penalty = 10k
    Coefficients C: penalty = 1k
    Coefficients D: penalty = 100
    Coefficients E: penalty = 10

  Tournament results (just top 4 players)
     +2.4  eval5/D
     +1.8  eval5/E
     +0.1  eval5/C
     -4.3  eval4/A

  Tournament results (bottom 4 players)
      +15.7  eval4/A
      +14.5  eval5/C
       +4.2  eval5/B
      -34.4  eval5/A

  From the difference between eval5/A and eval5/B it's clear the random subpositions help a lot.
  Trying subpositions with eval4. With penalty 100, this is coefficient set B.

  Tournament results:
      +10.4  eval4/B
       -0.3  eval5/D
       -1.0  eval5/E
       -2.5  eval5/C
       -6.6  eval4/A

  If random subpositions are good, are more better? Trying new evals with 20% random subpositions instead of 10%.
  These are eval4/C and eval5/F, both with penalty 100.

  Tournament results:
     +10.7  eval4/C
      +2.0  eval4/B
      -5.0  eval5/F
      -7.7  eval5/D

Now 100% random subpositions. 4-D and 5-H.

    Tournament results:
    +12.0  eval4-D-1
     +6.3  eval4-C-1
     -9.1  eval5-H-1
     -9.2  eval5-F-1

More seems better, at least for eval4-D.

### X-square coefficients

Eval4 coefficients are positive for x-squares at depths < approximately 22. This is stupid.

Tried a tournament with "Charlie", a coefficient set for eval4 that has negative values for x-squares (in fact, I just copied eval4-D's coefficients from 30 empties to all empties).

Tournament results:
+20.1  eval4-Charlie-1
 +5.9  eval4-D-1
 +1.6  eval4-C-1
-13.7  eval5-H-1
-13.9  eval5-F-1

Clearly there is a problem here.

### search depth

Played Charlie:depth 1 vs Charlie:depth 2. average result = -21.0 +/- 0.14. T ~  -152.

4D:1 vs 4D:2. average result -4.93 +/- 0.14. T ~ -36.4

4D:2 can more effectively take x-squares, which is hurting its performance (I think).

### Non-random positions

Are the non-random positions hurting? Try generating positions without the main line: 4-E and 5-I.
Figuring out the coefficients is a lot faster with the non-random positions; perhaps the many copies of each game position cause a lot of off-diagonal entries in the conjugate gradient matrix?

4E still wants to take x-squares around 20 empty.

    Tournament results:
    +19.0  eval4-Charlie-1
     +4.2  eval4-E-1
     +3.4  eval4-D-1
    -11.2  eval5-I-1
    -15.5  eval5-H-1

So removing the non-random positions helps! We'll do that.

### Bad Playouts?

Possibly part of the x-square problem is that Eval4-A, which generates the playouts, is messed up. Try again using Charlie to generate the playouts.

New players: 5J, 4F.

    Tournament results:
    +11.6  eval4-F-1
     +8.8  eval5-J-1
     +5.8  eval4-Charlie-1
     -5.3  eval4-E-1
    -21.0  eval5-I-1

* Using better playouts improved the results by an average of 23 disks.

Clearly the quality of the playouts has a massive impact on the evaluation function. Obviously improving the evaluation
function is one way to improve the playouts, but another is to increase the search depth. Let's see how much better these
new players are at increased search depth:

    Tournament results:
    +26.7  eval5-J-2
     +6.8  eval4-F-2
     +2.6  eval4-Charlie-2
     -8.8  eval5-J-1
     -9.2  eval4-F-1
    -18.1  eval4-Charlie-1

* Going to 2 ply helps by an average of 24 disks. This is much larger than the difference in the evals.
* At 2 ply, eval5 is better than eval4. eval5:1 (1 ply) did much better against the 2-ply bots than eval4:1. Probably the mobility term?

Since I'm going home, I will generate pvs using playouts from 5J:2 to see if that will generate even better coefficients.
The new coefficient sets will be 4G and 5K.

    Tournament results:
    +18.6  eval5-K-2
    +13.7  eval5-J-2
     -8.2  eval4-F-2
     -9.9  eval4-G-2
    -14.2  eval4-Charlie-2

The new coefficients helped by an average of 3 disks - not huge but better than a stick in the eye.

### Potential Mobility ###

One obvious weakness of the bots play is potential mobility - they are perfectly happy to have lots of boundary disks.

New evaluator 6 uses pot mob as a pattern. The coefficients on it are very large even in the endgame - perhaps this
will help our endgame play.

    Tournament results:
    +43.5  6A:2
    +12.6  5K:2
    -12.0  4G:2
    -15.3  6A:1
    -28.8  5K:1

Obviously this is a keeper.

Move Sorting
============

Trying potential mobility in Move Sorting.

### Without potential mobility ###

    914 [ 913- 917] ms. 8.40 Mn; 9.18 Mn/s; 109 ns/n

    Node fractions by depth:
     1: 33.7%
     2: 25.7%
     3: 16.9%
     4: 10.1%
     5:  6.0%
     6:  3.7%       First cut: 89%. Wasted: 0.15
     7:  2.1%       First cut: 85%. Wasted: 0.22
     8:  1.1%       First cut: 83%. Wasted: 0.26
     9:  0.51%      First cut: 80%. Wasted: 0.31
    10:  0.18%      First cut: 78%. Wasted: 0.36
    11:  0.063%     First cut: 78%. Wasted: 0.33
    12:  0.0095%

### With potential mobility ###

    887 [ 876- 894] ms. 7.99 Mn; 9.02 Mn/s; 111 ns/n

    Node fractions by depth:
     1: 33.6%
     2: 25.7%
     3: 16.8%
     4: 10.1%
     5:  5.9%
     6:  3.7%       First cut: 90%. Wasted: 0.14
     7:  2.1%       First cut: 86%. Wasted: 0.20
     8:  1.1%       First cut: 85%. Wasted: 0.23
     9:  0.53%      First cut: 83%. Wasted: 0.28
    10:  0.19%      First cut: 80%. Wasted: 0.32
    11:  0.067%     First cut: 81%. Wasted: 0.28
    12:  0.010%

    Predicted node type distribution:
    [ 5] ALL 37%, PV  0%, CUT 63%
    [ 6] ALL 36%, PV  0%, CUT 64%
    [ 7] ALL 31%, PV  0%, CUT 68%
    [ 8] ALL 32%, PV  1%, CUT 67%
    [ 9] ALL 25%, PV  2%, CUT 73%
    [10] ALL 31%, PV  5%, CUT 64%
    [11] ALL 11%, PV 15%, CUT 74%
    [12] ALL  0%, PV 100%, CUT  0%

After slightly tuning move ordering weights using SolverTuner, node count goes down to 7.97Mn.

With all move ordering weights non-final
    896 [ 893- 899] ms. 7.97 Mn; 8.88 Mn/s; 113 ns/n
    893 [ 891- 895] ms. 7.97 Mn; 8.94 Mn/s; 112 ns/n

With all move-ordering weights final:
    895 [ 893- 899] ms. 7.97 Mn; 8.90 Mn/s; 112 ns/n

final and subtracting 5 makes some weights 0, so the compiler can eliminate the shifts:
    887 [ 881- 889] ms. 8.04 Mn; 9.08 Mn/s; 110 ns/n

These seem to bounce around a lot, so not sure how much all this is helping.

### Results from version checked in ###

    Typical  873 [ 862- 878] ms. 7.97 Mn; 9.13 Mn/s; 110 ns/n

    Node fractions by depth:
     1: 33.6%
     2: 25.7%
     3: 16.9%
     4: 10.1%
     5:  6.0%
     6:  3.7%       First cut: 89%. Wasted: 0.14
     7:  2.1%       First cut: 85%. Wasted: 0.21
     8:  1.1%       First cut: 84%. Wasted: 0.24
     9:  0.53%      First cut: 81%. Wasted: 0.30
    10:  0.19%      First cut: 78%. Wasted: 0.36
    11:  0.067%     First cut: 78%. Wasted: 0.32
    12:  0.010%

    Predicted node type distribution:
    [ 5] ALL 37%, PV  0%, CUT 63%
    [ 6] ALL 36%, PV  0%, CUT 63%
    [ 7] ALL 31%, PV  0%, CUT 69%
    [ 8] ALL 33%, PV  1%, CUT 66%
    [ 9] ALL 24%, PV  2%, CUT 74%
    [10] ALL 32%, PV  5%, CUT 63%
    [11] ALL 10%, PV 15%, CUT 75%
    [12] ALL  0%, PV 100%, CUT  0%

    31,106,608 finds and 9,049,840 stores. 269,440 / 718,992 / 1,664 alpha/beta/pv cuts. 703,504 useless finds.

Eval
====

Try using edge patterns for eval: this is eval 7A. Compare to older non-edge-pattern evals 6A and 5K.

    Tournament results:
    +46.2  7A:2
    +16.5  6A:2
    -13.0  7A:1
    -15.2  5K:2
    -34.5  6A:1


Found a bug in evalPlayer (evaluated position using the mover's moves for both moverMoves and enemyMoves).
All previous tournament results are thus suspect as are the values from playouts.

Reran the previous tournament:
    +40.0  7A:2
    +20.6  6A:2
     +4.2  5K:2
    -20.9  7A:1
    -43.9  6A:1

Midgame Speed
=============
It's getting painfully slow even at 2 ply.

Check node count of a SelfPlaySet, 7A:2 vs 7A:2
    110,538,379 position evaluations performed.

Try corners first, x-squares last:
    106,405,074 position evaluations performed.

Coefficient calculation
=======================

7A:2 (no bug) surely produces much better playouts than 5J:2 (with bug). Used 7A:2 as playout player and
reran coefficients for 6B and 7B. [Coefficient index frequency distribution][frequency.txt]

    Tournament results:
    +30.0  7B:2
     +1.2  6B:2
     -5.4  7A:2
    -25.8  6A:2

Play vs NTest
=============

Set up to play vs Ntest. This is slow because of inter-process communication, so I cut off before the end, but 7A loses quite badly.
    7A:2 vs NTest:2  after 15,000 matches, average result = -59.2 +/- 0.24. T ~  -248
    7A:2 vs NTest:1  after 15,000 matches, average result = -39.7 +/- 0.27. T ~  -150

Whoops, just realized 7B is the current version, and much better.
    7B:2 vs NTest:1  after 10,000 matches, average result = -17.0 +/- 0.34. T ~ -50.3

Coefficients 8A now available:
    8A:2 vs NTest:1  after 15,000 matches, average result = -11.2 +/- 0.27. T ~ -41.2
    8A:2 vs NTest:2  after 10,000 matches, average result = -33.7 +/- 0.31. T ~  -110

Still have a ways to go.

Coefficient calculation
=======================

Add PotMobs2 as an evaluation term. Coefficients are fairly small compared to PotMobs, range from lowest coefficient to highest within MoverPotMobs and also EnemyPotMobs is typically ~7. This is surely correlated with PotMobs, too, so I wasn't expecting too much improvement.

    7B:2 vs 8A:2: average result = -5.4

While small, I'll keep it. We're not doing performance tuning yet.

Add all rows as evaluation terms instead of just edges.

    9A:2 vs 8A:2: average result = 7.9
    9A:2 vs NTest:1: average result = -4.7

Found a bug if there was a pass in midgame search. Fixed!

    9A:2 vs NTest:1: average result = -4.2

Added eval 'a' which uses diagonal lines also. Also recalculated coefficients 9 using 9A instead of older 7A;
this is coefficient set 9B.

    a1:2 vs NTest:1: average result = 6.3

    Tournament results:
    +11.3  a1:2
     +2.3  9B:2
    -13.6  9A:2

Added eval 'b' using 3x3 corner blocks.

    b1:2 vs NTest:2: average result = -12.7

    Tournament results:
    +11.3  b1:2
     -1.3  a1:2
    -10.0  9b:2

Deep Solver
===========
[86d7a78] Starting statistics for DeepSolverTimer at depth 20:
    6,787 ms elapsed; 70,092,939 total nodes

    Node fractions by depth:
     1: 31.8%
     2: 24.0%
     3: 16.8%
     4:  9.9%
     5:  6.6%
     6:  4.2%       First cut: 93%. Wasted: 0.10
     7:  2.9%       First cut: 93%. Wasted: 0.10
     8:  1.6%       First cut: 91%. Wasted: 0.13
     9:  1.1%       First cut: 93%. Wasted: 0.10
    10:  0.49%      First cut: 89%. Wasted: 0.16
    11:  0.31%      First cut: 92%. Wasted: 0.11
    12:  0.12%      First cut: 88%. Wasted: 0.19
    13:  0.073%     First cut: 91%. Wasted: 0.13
    14:  0.024%     First cut: 86%. Wasted: 0.23
    15:  0.013%     First cut: 89%. Wasted: 0.16
    16:  0.0036%    First cut: 83%. Wasted: 0.31
    17:  0.0017%    First cut: 87%. Wasted: 0.20
    18:  0.00039%   First cut: 78%. Wasted: 0.40
    19:  0.00015%   First cut: 82%. Wasted: 0.35
    20:  1.4e-05%

    Predicted node type distribution:
    [ 5] ALL 35%, PV  0%, CUT 65%
    [ 6] ALL 47%, PV  0%, CUT 53%
    [ 7] ALL 29%, PV  0%, CUT 71%
    [ 8] ALL 48%, PV  0%, CUT 52%
    [ 9] ALL 24%, PV  0%, CUT 76%
    [10] ALL 49%, PV  0%, CUT 51%
    [11] ALL 20%, PV  0%, CUT 80%
    [12] ALL 48%, PV  0%, CUT 52%
    [13] ALL 18%, PV  0%, CUT 82%
    [14] ALL 46%, PV  0%, CUT 54%
    [15] ALL 16%, PV  0%, CUT 84%
    [16] ALL 42%, PV  0%, CUT 57%
    [17] ALL 15%, PV  1%, CUT 84%
    [18] ALL 38%, PV  4%, CUT 59%
    [19] ALL  5%, PV 10%, CUT 86%
    [20] ALL  0%, PV 100%, CUT  0%

    33,688,406 finds and 8,614,016 stores. 312,809 / 347,649 / 21 alpha/beta/pv cuts. 21,595 useless finds.

Hash Table
----------
6510 ms elapsed: Separate hash-tables by depth (64 hash buckets per depth)

Deep Move Sorting
-----------------
9,183 ms elapsed; 75,809,707 total nodes: Eval-based move sort at depth >= 12, with no FF adjustment
5,252 ms elapsed; 43,713,320 total nodesL Eval -based move sort at depth >= 12, with DEEP_MOBILITY_WEIGHT = 4.

Speed up eval
-------------
4,969 ms elapsed; 43,713,320 total nodes

Running SolverTimer (so HotSpot warms up):
Typical 4245 [4239-4253] ms. 43.7 Mn; 10.3 Mn/s; 97.2 ns/n

Hash Table
----------
Different hash size per depth. Checking total node count. DeepSolverTest from 20 empty.
    log buckets   result
             15   5,480 ms elapsed; 34,322,025 total nodes
             12   4,296 ms elapsed; 35,283,870 total nodes
             10   4,348 ms elapsed; 36,750,608 total nodes
              8   4,541 ms elapsed; 39,237,209 total nodes
              5   5,319 ms elapsed; 48,065,104 total nodes

          10-12   4,237 ms elapsed; 35,652,697 total nodes
          10-15   5,299 ms elapsed; 35,035,733 total nodes

Presumably the reason 15 is slower is due to hitting RAM instead of L3 cache. Thus, keeping log buckets at 10
(even though 12 is faster) on the assumption that, running multiple cores simultaneously will use even more cache
and thus will be optimal at 10.

Better idea: use a small hash at low empties and a larger hash at higher empties; thus the small hash will fit in cache
while the larger hash will hold more valuable information where it's worth it to go out to RAM.

SolverTimer
===========
Rechecking SolverTimer in light of the previous section. At depth12, a lot of its time is spent in HashTable.clear()
making sure we don't cheat on the benchmarks. Changed it so HashTable.clear() only clears entries that will used by
the test, so it only clears the section between 6 empties and the number of empties in the position.

Eval-based Move Sorting
=======================
An idea that didn't work very well: alter eval-based sort depth based on node type.

Some work on move sorting. Alter sorting based on evaluation vs (alpha, beta).

Idea 1: If move eval is > beta + 20, it's going to cut off. Weight enemy mobility higher relative to score.
 This helps slightly. Halve the excess eval over beta+20. Works better than quartering it.

Idea 2: Don't sort if the position is hopeless and nEmpty is close to MIN_EVAL_SORT_DEPTH. Hopeless is defined as eval < alpha-15.
 This also helps slightly. Best parameters are MIN_EVAL_SORT_DEPTH stays at 12, and chop off evals if depth <= MIN_EVAL_SORT_DEPTH+2.

With both of these in place, DeepSolverTimer(20) returns
    3,482 ms elapsed; 35,746,412 total nodes

Tuning the beta margin for minimum nodes with SolverTuner yields BETA_MARGIN=24.
    3,481 ms elapsed; 35,674,679 total nodes

Another idea: When sorting, choose a move where the opponent has lower potential mobility in addition to actual mobility,
thus allowing future moves to be fast. Keeping this, even though it's slower at depth = 20, because it's faster at depth = 22.
    3,496 ms elapsed; 34,645,403 total nodes   at depth 20
   18,806 ms elapsed; 186,129,822 total nodes  at depth 22

Evaluate with a 2-ply search if nEmpty > 16:
    18,267 ms elapsed; 179,094,367 total nodes
    18,132 ms elapsed; 175,586,548 total nodes, nEmpty >= 16
    18,219 ms elapsed; 173,957,172 total nodes, nEmpty >= 15
    19,076 ms elapsed; 171,288,583 total nodes, nEmpty >= 14
going with nEmpty >= 16.

Hash Table
==========
Tried increasing the table size at higher depths - helps a little in terms of nodes but not visible in the timing, so did not keep it.

Coefficient calculator
======================
Using dense weights to estimate coefficients b (straight lines, mobility approximations, corner 3x3 boxes).
Need to determine a function which approximates coefficients as a function of mobility, potMobs, potMobs2.
Use a regression to determine, for each feature, which of the three functions {ax+b, a*log(x)+b, a*sqrt(x)+b}
best approximates the feature values. Looking at coefficients b1 at 24 empties, and discarding instances with few
occurrences, both Mover and Enemy mobility are best fit by sqrt; Mover and Enemy potMobs are best fit by x; and
Mover and Enemy potMobs2 are best fit by log(x). Not sure what to do here, so using sqrt(x) for the dense weight
for all these as I calculate b2 coefficients, the first using dense weights.

After estimating coefficients at 24 empty using sqrt(x) for all six functions, sqrt() is now the best fitting
of the functions for mobility and potMob2. PotMob still fits best to a line.

    b1:2 vs b2:2: average result = 13.3
This experiment appears not to work.

b3 is calculated using dense features only for mover and enemy mobility, with the feature value proportional to sqrt(mobility).
    b3:2 vs b1:2: average result = -0.8

This also doesn't work.

Cutoff statistics
=================
[0723bde] Running DeepSolver at 22 empty. We want to predict whether the solver value for a move is >= beta ('CUT'),
<= alpha ('ALL') or in the window ('PV') - call this the 'actual node type', in contrast to the 'predicted node type'
which is what is represented by the nodeType variable.

For each node at depth >=11, do a static eval on the position using b1.
Create a bucket based on the static eval relation to the (alpha, beta) window: above beta (and by how much),
below alpha (and by how much), or in the window.
Calculate the probabilities of each actual node type conditioned on the bucket.

    <α 92-95:   0% CUT,   0% PV, 100% ALL           1 nodes
    <α 88-91:   0% CUT,   0% PV, 100% ALL           6 nodes
    <α 84-87:   0% CUT,   0% PV, 100% ALL          15 nodes
    <α 80-83:   0% CUT,   0% PV, 100% ALL          28 nodes
    <α 76-79:   0% CUT,   0% PV, 100% ALL         112 nodes
    <α 72-75:   0% CUT,   0% PV, 100% ALL         259 nodes
    <α 68-71:   0% CUT,   0% PV, 100% ALL         602 nodes
    <α 64-67:   0% CUT,   0% PV, 100% ALL       1,144 nodes
    <α 60-63:   0% CUT,   0% PV, 100% ALL       2,321 nodes
    <α 56-59:   0% CUT,   0% PV, 100% ALL       4,460 nodes
    <α 52-55:   0% CUT,   0% PV, 100% ALL       8,176 nodes
    <α 48-51:   0% CUT,   0% PV, 100% ALL      13,121 nodes
    <α 44-47:   0% CUT,   0% PV, 100% ALL      19,770 nodes
    <α 40-43:   0% CUT,   0% PV, 100% ALL      26,678 nodes
    <α 36-39:   0% CUT,   0% PV, 100% ALL      32,119 nodes
    <α 32-35:   0% CUT,   0% PV, 100% ALL      36,898 nodes
    <α 28-31:   0% CUT,   0% PV, 100% ALL      39,576 nodes
    <α 24-27:   1% CUT,   0% PV,  99% ALL      40,638 nodes
    <α 20-23:   2% CUT,   0% PV,  98% ALL      39,306 nodes
    <α 16-19:   4% CUT,   0% PV,  96% ALL      36,233 nodes
    <α 12-15:  10% CUT,   0% PV,  90% ALL      32,406 nodes
    <α  8-11:  20% CUT,   0% PV,  80% ALL      29,545 nodes
    <α  4- 7:  37% CUT,   0% PV,  63% ALL      28,506 nodes
    <α  0- 3:  58% CUT,   0% PV,  42% ALL      32,755 nodes
    pv      :  46% CUT,  51% PV,   3% ALL       1,420 nodes
    >ß  0- 3:  78% CUT,   0% PV,  22% ALL      39,933 nodes
    >ß  4- 7:  90% CUT,   0% PV,  10% ALL      45,314 nodes
    >ß  8-11:  96% CUT,   0% PV,   4% ALL      57,383 nodes
    >ß 12-15:  98% CUT,   0% PV,   2% ALL      71,633 nodes
    >ß 16-19:  99% CUT,   0% PV,   1% ALL      86,993 nodes
    >ß 20-23: 100% CUT,   0% PV,   0% ALL     101,264 nodes
    >ß 24-27: 100% CUT,   0% PV,   0% ALL     111,477 nodes
    >ß 28-31: 100% CUT,   0% PV,   0% ALL     116,082 nodes
    >ß 32-35: 100% CUT,   0% PV,   0% ALL     113,619 nodes
    >ß 36-39: 100% CUT,   0% PV,   0% ALL     103,106 nodes
    >ß 40-43: 100% CUT,   0% PV,   0% ALL      84,261 nodes
    >ß 44-47: 100% CUT,   0% PV,   0% ALL      63,049 nodes
    >ß 48-51: 100% CUT,   0% PV,   0% ALL      41,582 nodes
    >ß 52-55: 100% CUT,   0% PV,   0% ALL      25,349 nodes
    >ß 56-59: 100% CUT,   0% PV,   0% ALL      14,271 nodes
    >ß 60-63: 100% CUT,   0% PV,   0% ALL       7,853 nodes
    >ß 64-67: 100% CUT,   0% PV,   0% ALL       4,314 nodes
    >ß 68-71: 100% CUT,   0% PV,   0% ALL       2,258 nodes
    >ß 72-75: 100% CUT,   0% PV,   0% ALL       1,080 nodes
    >ß 76-79: 100% CUT,   0% PV,   0% ALL         574 nodes
    >ß 80-83: 100% CUT,   0% PV,   0% ALL         199 nodes
    >ß 84-87: 100% CUT,   0% PV,   0% ALL          83 nodes
    >ß 88-91: 100% CUT,   0% PV,   0% ALL          14 nodes
    >ß 92-95: 100% CUT,   0% PV,   0% ALL          10 nodes
    >ß 96-99: 100% CUT,   0% PV,   0% ALL           1 nodes

    PRED_ALL:   8% CUT,   0% PV,  92% ALL     402,461 nodes
    PRED_PV :   0% CUT, 100% PV,   0% ALL         132 nodes
    PRED_CUT:  97% CUT,   0% PV,   3% ALL   1,115,204 nodes

    Statistics calculated for 1,517,797 total nodes

The same statistics, but collected only for PRED_CUT nodes:

    <α 52-55:   0% CUT,   0% PV, 100% ALL           1 nodes
    <α 48-51:   0% CUT,   0% PV, 100% ALL           4 nodes
    <α 44-47:   0% CUT,   0% PV, 100% ALL          10 nodes
    <α 40-43:   0% CUT,   0% PV, 100% ALL          13 nodes
    <α 36-39:   2% CUT,   0% PV,  98% ALL          61 nodes
    <α 32-35:   0% CUT,   0% PV, 100% ALL         157 nodes
    <α 28-31:   3% CUT,   0% PV,  97% ALL         301 nodes
    <α 24-27:   6% CUT,   0% PV,  94% ALL         527 nodes
    <α 20-23:  10% CUT,   0% PV,  90% ALL       1,101 nodes
    <α 16-19:  17% CUT,   0% PV,  83% ALL       1,977 nodes
    <α 12-15:  31% CUT,   0% PV,  69% ALL       3,647 nodes
    <α  8-11:  43% CUT,   0% PV,  56% ALL       6,560 nodes
    <α  4- 7:  57% CUT,   1% PV,  42% ALL      10,875 nodes
    <α  0- 3:  72% CUT,   1% PV,  27% ALL      19,079 nodes
    pv      :  55% CUT,  41% PV,   4% ALL       1,080 nodes
    >ß  0- 3:  85% CUT,   0% PV,  15% ALL      30,833 nodes
    >ß  4- 7:  93% CUT,   0% PV,   7% ALL      40,015 nodes
    >ß  8-11:  97% CUT,   0% PV,   3% ALL      54,126 nodes
    >ß 12-15:  99% CUT,   0% PV,   1% ALL      69,807 nodes
    >ß 16-19:  99% CUT,   0% PV,   1% ALL      85,945 nodes
    >ß 20-23: 100% CUT,   0% PV,   0% ALL     100,638 nodes
    >ß 24-27: 100% CUT,   0% PV,   0% ALL     111,138 nodes
    >ß 28-31: 100% CUT,   0% PV,   0% ALL     115,902 nodes
    >ß 32-35: 100% CUT,   0% PV,   0% ALL     113,508 nodes
    >ß 36-39: 100% CUT,   0% PV,   0% ALL     103,042 nodes
    >ß 40-43: 100% CUT,   0% PV,   0% ALL      84,234 nodes
    >ß 44-47: 100% CUT,   0% PV,   0% ALL      63,036 nodes
    >ß 48-51: 100% CUT,   0% PV,   0% ALL      41,582 nodes
    >ß 52-55: 100% CUT,   0% PV,   0% ALL      25,348 nodes
    >ß 56-59: 100% CUT,   0% PV,   0% ALL      14,271 nodes
    >ß 60-63: 100% CUT,   0% PV,   0% ALL       7,853 nodes
    >ß 64-67: 100% CUT,   0% PV,   0% ALL       4,314 nodes
    >ß 68-71: 100% CUT,   0% PV,   0% ALL       2,258 nodes
    >ß 72-75: 100% CUT,   0% PV,   0% ALL       1,080 nodes
    >ß 76-79: 100% CUT,   0% PV,   0% ALL         574 nodes
    >ß 80-83: 100% CUT,   0% PV,   0% ALL         199 nodes
    >ß 84-87: 100% CUT,   0% PV,   0% ALL          83 nodes
    >ß 88-91: 100% CUT,   0% PV,   0% ALL          14 nodes
    >ß 92-95: 100% CUT,   0% PV,   0% ALL          10 nodes
    >ß 96-99: 100% CUT,   0% PV,   0% ALL           1 nodes

    PRED_CUT:  97% CUT,   0% PV,   3% ALL   1,115,204 nodes

And similarly for PRED_ALL nodes:

    <α 92-95:   0% CUT,   0% PV, 100% ALL           1 nodes
    <α 88-91:   0% CUT,   0% PV, 100% ALL           6 nodes
    <α 84-87:   0% CUT,   0% PV, 100% ALL          15 nodes
    <α 80-83:   0% CUT,   0% PV, 100% ALL          28 nodes
    <α 76-79:   0% CUT,   0% PV, 100% ALL         112 nodes
    <α 72-75:   0% CUT,   0% PV, 100% ALL         259 nodes
    <α 68-71:   0% CUT,   0% PV, 100% ALL         602 nodes
    <α 64-67:   0% CUT,   0% PV, 100% ALL       1,144 nodes
    <α 60-63:   0% CUT,   0% PV, 100% ALL       2,321 nodes
    <α 56-59:   0% CUT,   0% PV, 100% ALL       4,460 nodes
    <α 52-55:   0% CUT,   0% PV, 100% ALL       8,175 nodes
    <α 48-51:   0% CUT,   0% PV, 100% ALL      13,117 nodes
    <α 44-47:   0% CUT,   0% PV, 100% ALL      19,760 nodes
    <α 40-43:   0% CUT,   0% PV, 100% ALL      26,665 nodes
    <α 36-39:   0% CUT,   0% PV, 100% ALL      32,058 nodes
    <α 32-35:   0% CUT,   0% PV, 100% ALL      36,741 nodes
    <α 28-31:   0% CUT,   0% PV, 100% ALL      39,275 nodes
    <α 24-27:   1% CUT,   0% PV,  99% ALL      40,111 nodes
    <α 20-23:   1% CUT,   0% PV,  99% ALL      38,205 nodes
    <α 16-19:   3% CUT,   0% PV,  97% ALL      34,256 nodes
    <α 12-15:   7% CUT,   0% PV,  93% ALL      28,759 nodes
    <α  8-11:  13% CUT,   0% PV,  87% ALL      22,985 nodes
    <α  4- 7:  24% CUT,   0% PV,  76% ALL      17,631 nodes
    <α  0- 3:  38% CUT,   0% PV,  62% ALL      13,676 nodes
    pv      :  29% CUT,  69% PV,   2% ALL         208 nodes
    >ß  0- 3:  55% CUT,   0% PV,  45% ALL       9,100 nodes
    >ß  4- 7:  69% CUT,   0% PV,  31% ALL       5,299 nodes
    >ß  8-11:  81% CUT,   0% PV,  19% ALL       3,257 nodes
    >ß 12-15:  88% CUT,   0% PV,  12% ALL       1,826 nodes
    >ß 16-19:  94% CUT,   0% PV,   6% ALL       1,048 nodes
    >ß 20-23:  98% CUT,   0% PV,   2% ALL         626 nodes
    >ß 24-27:  98% CUT,   0% PV,   2% ALL         339 nodes
    >ß 28-31:  99% CUT,   0% PV,   1% ALL         180 nodes
    >ß 32-35:  99% CUT,   0% PV,   1% ALL         111 nodes
    >ß 36-39: 100% CUT,   0% PV,   0% ALL          64 nodes
    >ß 40-43: 100% CUT,   0% PV,   0% ALL          27 nodes
    >ß 44-47: 100% CUT,   0% PV,   0% ALL          13 nodes
    >ß 52-55: 100% CUT,   0% PV,   0% ALL           1 nodes

    PRED_ALL:   8% CUT,   0% PV,  92% ALL     402,461 nodes

    Statistics calculated for 402,461 total nodes

Coefficient reuse
=================
Instead of using separate coefficients for each empty, we reuse coefficients. While the original plan was to decrease
memory consumption and thus cache misses, we first see how it affects the node count by simply loading multiple copies
of the coefficients. Modified code for the coefficient loader:
            nEmpty = (nEmpty&~7)+4;

Test using DeepSolverTimer from 20 empties

 Original: 33,319,212 total nodes. Typical timings 3552 [3529-2570], 3559 [3530-3588]
 Modified: 32,930,096 total nodes. Typical timings 3477 [3460-3517], 3525 [3506-3561], 3572 [3508-3652]

 So this seems a slight improvement even without the cache consumption benefit.

 Reusing the coefficients (so lower memory consumption):
3542 [3522-3594], 3541 [3513-3574]

This is not an unambiguous win. Testing a self-play session between the combined coefficients and the original:
(b1 is the original version, b1x is the modified version)

    b1:2 vs b1x:2: average result = 2.1

Vary that method as follows: instead of combining all coefficients for an 8-wide range of nEmpty into one set,
use separate sets for odd and even parity.

    b1:2 vs b1x:2: average result = 0.5

Also tried separate parity sets only at depth <=12 on the theory parity only matters at low # empties.

    b1:2 vs b1x:2: average result = 1.8

Going with separate parity as a reasonable compromise.

Stable Disks
============
Checking stable disks at 6 empty. If edge disks >= 1/2 the necessary stables for a cutoff, perform a full stability
calculation. Cut off if stable disks force a cutoff. How often does this occur at various depths?

[18] stable beta cuts: 0.2%, alpha cuts: 1.3%. 17.5% received full stability calc out of 354,372 total nodes
[20] stable beta cuts: 0.4%, alpha cuts: 1.8%. 23.2% received full stability calc out of 1,412,465 total nodes
[22] stable beta cuts: 0.4%, alpha cuts: 4.0%. 28.6% received full stability calc out of 7,576,837 total nodes
[24] stable beta cuts: 0.8%, alpha cuts: 2.5%. 28.0% received full stability calc out of 43,539,435 total nodes
[26] stable beta cuts: 0.8%, alpha cuts: 2.8%. 28.5% received full stability calc out of 269,728,279 total nodes
[28] stable beta cuts: 0.8%, alpha cuts: 3.3%. 29.0% received full stability calc out of 1,380,627,246 total nodes
[30] stable beta cuts: 1.9%, alpha cuts: 2.7%. 30.2% received full stability calc out of 9,381,891,258 total nodes

Now try move sorting to create stable disks.
1. In the eval-based sort, if eval > beta + BETA_MARGIN, add (# stable disks/2) to the move sort eval.
[18] stable beta cuts: 0.2%, alpha cuts: 1.4%. 17.7% received full stability calc out of 354,324 total nodes
[20] stable beta cuts: 0.5%, alpha cuts: 1.9%. 23.5% received full stability calc out of 1,413,527 total nodes
[22] stable beta cuts: 0.5%, alpha cuts: 4.2%. 29.2% received full stability calc out of 7,562,330 total nodes
[24] stable beta cuts: 0.8%, alpha cuts: 2.7%. 28.9% received full stability calc out of 43,267,355 total nodes

2. As above, but add (# stable disks * 2) to the move sort eval.
[18] stable beta cuts: 0.2%, alpha cuts: 1.4%. 18.3% received full stability calc out of 357,627 total nodes
[20] stable beta cuts: 0.5%, alpha cuts: 2.0%. 24.6% received full stability calc out of 1,439,041 total nodes
[22] stable beta cuts: 0.5%, alpha cuts: 4.5%. 30.7% received full stability calc out of 7,731,615 total nodes
[24] stable beta cuts: 1.0%, alpha cuts: 3.1%. 31.0% received full stability calc out of 44,458,704 total nodes
[26] stable beta cuts: 0.9%, alpha cuts: 3.0%. 29.6% received full stability calc out of 267,437,373 total nodes

3. as 2. but non-eval-based sort (sort with ETC, down to 6 empties) adds 20*stable disk count to eval
[18] stable beta cuts: 0.4%, alpha cuts: 2.5%. 24.4% received full stability calc out of 361,337 total nodes
[20] stable beta cuts: 0.7%, alpha cuts: 3.5%. 32.1% received full stability calc out of 1,461,425 total nodes
[22] stable beta cuts: 0.7%, alpha cuts: 7.0%. 39.9% received full stability calc out of 7,915,156 total nodes
[24] stable beta cuts: 1.7%, alpha cuts: 5.1%. 40.4% received full stability calc out of 45,517,343 total nodes
[26] stable beta cuts: 2.0%, alpha cuts: 5.6%. 41.4% received full stability calc out of 282,737,338 total nodes

4. as 3. but the non-eval based addition is 20* edge stable count.
[18] stable beta cuts: 0.3%, alpha cuts: 1.9%. 25.5% received full stability calc out of 361,625 total nodes
[20] stable beta cuts: 0.6%, alpha cuts: 2.8%. 33.3% received full stability calc out of 1,449,209 total nodes
[22] stable beta cuts: 0.6%, alpha cuts: 5.9%. 41.3% received full stability calc out of 7,823,242 total nodes
[24] stable beta cuts: 1.3%, alpha cuts: 4.1%. 42.3% received full stability calc out of 45,096,462 total nodes

I think it's all bogus. I'm taking out the sorting but, for now, leaving in the check at 6 empty.

Current DeepSolverTimer statistics
==================================
From 24 empties

    104,764 ms elapsed; 883,116,853 total nodes


    Statistics calculated for 0 total nodes
    ## Stable disk counts at 6 empty ##
     6:        33
     7:       231
     8:     2,789
     9:     6,452
    10:     9,739
    11:    11,706
    12:    16,798
    13:    28,447
    14:    48,974
    15:    80,827
    16:   164,341
    17:   282,488
    18:   432,193
    19:   615,670
    20:   776,163
    21:   906,626
    22:   962,578
    23:   971,642
    24:   949,636
    25:   899,544
    26:   835,181
    27:   756,107
    28:   664,942
    29:   567,503
    30:   467,684
    31:   378,605
    32:   286,460
    33:   218,520
    34:   161,863
    35:   119,013
    36:    86,200
    37:    61,198
    38:    42,390
    39:    29,550
    40:    20,273
    41:    14,082
    42:     9,737
    43:     6,461
    44:     4,394
    45:     2,984
    46:     2,013
    47:     1,245
    48:       807
    49:       609
    50:       427
    51:       210
    52:       105
    53:       106
    54:        66
    55:        27
    56:        10
    57:        10
    58:        13
    stable beta cuts: 0.8%, alpha cuts: 2.6%. 28.2% received full stability calc out of 42,284,788 total nodes

    Node fractions by depth:
     1: 29.9%
     2: 22.8%
     3: 16.6%
     4: 10.0%
     5:  7.1%
     6:  4.8%       First cut: 93%. Wasted: 0.08
     7:  3.6%       First cut: 95%. Wasted: 0.07
     8:  2.0%       First cut: 93%. Wasted: 0.10
     9:  1.5%       First cut: 95%. Wasted: 0.06
    10:  0.72%      First cut: 92%. Wasted: 0.11
    11:  0.53%      First cut: 96%. Wasted: 0.06
    12:  0.22%      First cut: 94%. Wasted: 0.08
    13:  0.16%      First cut: 97%. Wasted: 0.04
    14:  0.057%     First cut: 94%. Wasted: 0.08
    15:  0.040%     First cut: 97%. Wasted: 0.04
    16:  0.013%     First cut: 94%. Wasted: 0.08
    17:  0.0083%    First cut: 97%. Wasted: 0.04
    18:  0.0023%    First cut: 94%. Wasted: 0.10
    19:  0.0014%    First cut: 95%. Wasted: 0.06
    20:  0.00034%   First cut: 93%. Wasted: 0.12
    21:  0.00018%   First cut: 93%. Wasted: 0.11
    22:  3.6e-05%   First cut: 91%. Wasted: 0.20
    23:  1.6e-05%   First cut: 90%. Wasted: 0.18
    24:  1.4e-06%

    Predicted node type distribution:
    [ 5] ALL 34%, PV  0%, CUT 66%
    [ 6] ALL 53%, PV  0%, CUT 47%
    [ 7] ALL 26%, PV  0%, CUT 74%
    [ 8] ALL 56%, PV  0%, CUT 44%
    [ 9] ALL 20%, PV  0%, CUT 80%
    [10] ALL 58%, PV  0%, CUT 42%
    [11] ALL 17%, PV  0%, CUT 83%
    [12] ALL 58%, PV  0%, CUT 42%
    [13] ALL 15%, PV  0%, CUT 85%
    [14] ALL 56%, PV  0%, CUT 44%
    [15] ALL 14%, PV  0%, CUT 86%
    [16] ALL 53%, PV  0%, CUT 47%
    [17] ALL 14%, PV  0%, CUT 86%
    [18] ALL 49%, PV  0%, CUT 51%
    [19] ALL 14%, PV  0%, CUT 86%
    [20] ALL 44%, PV  0%, CUT 55%
    [21] ALL 12%, PV  1%, CUT 87%
    [22] ALL 40%, PV  4%, CUT 56%
    [23] ALL  3%, PV  9%, CUT 88%
    [24] ALL  0%, PV 100%, CUT  0%

    495,057,021 finds and 115,528,785 stores. 4,320,910 / 4,679,570 / 8 alpha/beta/pv cuts. 238,709 useless finds.

FFO test
========
I can compare Novello to Zebra and ToolThought, both of which have node counts available on the internet.

    Zebra: <http://www.radagast.se/othello/ffotest.html>
    ToolThought:  <http://www.andreazinno.it/ffotest.html>
    Edax: inside the edax help file.

Note: Other programs were being run while the test was in progress, so times may be a bit slow.

    #40  A2  38     1.7s  20 empty   17.0 Mn
    #41  H4   0     2.0s  22 empty   17.5 Mn
    #42  G2   6     2.9s  22 empty   31.7 Mn
    #43  C7 -12     7.5s  23 empty   57.3 Mn
    #44  B8 -14     3.7s  23 empty   31.1 Mn
    #45  B2   6    37.9s  24 empty  378.2 Mn
    #46  B3  -8     9.7s  24 empty   86.4 Mn
    #47  G2   4     5.3s  25 empty   51.7 Mn
    #48  F6  28    89.5s  25 empty  774.5 Mn
    #49  E1  16    85.3s  26 empty  856.4 Mn
    #50  D8  10    80.2s  26 empty  569.9 Mn
    #51  E2   6    55.8s  27 empty  440.2 Mn
    #52  A3   0    71.1s  27 empty  594.5 Mn
    #53  D8  -2   648.5s  28 empty  5418.5 Mn
    #54  C7  -2  1043.9s  28 empty  10000.0 Mn
    #55  B7   0  2900.2s  29 empty  24284.6 Mn
    #56  H5   2   386.0s  29 empty  2873.1 Mn
    #57  A6 -10   690.6s  30 empty  5708.6 Mn
    #58  G1   4   639.5s  30 empty  6051.4 Mn
    #59  E8  64     0.0s  34 empty    0.0 Mn
    Total:       6761.3s             58.2 Gn


Comparison with edax
--------------------
From the edax help file: for edax 4.1, running on 4 cores on a Q9650 3.6GHz Quad core Intel CPU with 8GiB of memory,
Total time for edax ffo 40-59  0:05:05.44 	82.9 MN/s.

              edax	novello	ratio
    time,s  305.44    6761    22.1
    MN/s      82.9     8.6     9.6
    MN       25320	 58240     2.3

Novello's node count is much worse than Zebra and ToolThought too.

Attempts to fix
---------------
Is it the hash table size? Multiply hash table size by 16 (above 8 empty) - this gets it up to 2^18 buckets per empty at
 >= 12 empty and rerun:

     #40  A2  38     1.7s  20 empty     16.3 Mn
     #41  H4   0     2.0s  22 empty     16.6 Mn
     #42  G2   6     3.0s  22 empty     30.9 Mn
     #43  C7 -12     7.9s  23 empty     55.4 Mn
     #44  B8 -14     3.8s  23 empty     29.6 Mn
     #45  B2   6    37.9s  24 empty    359.5 Mn
     #46  B3  -8    10.1s  24 empty     85.3 Mn
     #47  G2   4     5.7s  25 empty     50.6 Mn
     #48  F6  28    92.4s  25 empty    748.5 Mn
     #49  E1  16    88.5s  26 empty    830.0 Mn
     #50  D8  10    82.9s  26 empty    536.9 Mn
     #51  E2   6    56.4s  27 empty    421.6 Mn
     #52  A3   0    71.9s  27 empty    577.8 Mn
     #53  D8  -2   655.8s  28 empty   5142.9 Mn
     #54  C7  -2  1060.4s  28 empty   9577.8 Mn
     #55  B7   0  3016.4s  29 empty  23375.6 Mn
     #56  H5   2   412.3s  29 empty   2772.8 Mn
     #57  A6 -10   716.4s  30 empty   5503.6 Mn
     #58  G1   4   652.2s  30 empty   5819.3 Mn
     #59  E8  64     0.0s  34 empty      0.0 Mn
     Total:       6977.7s               55.0 Gn

This is slower (though timings are somewhat suspect) and only drops the node count by 5%. Apparently it is not the
magic bullet. Reverting.

Going to try ordering by midgame search cost. This will require a midgame search! So that's up next.

Midgame Search
==============
Main uses:

1. Calculating midgame search cost in order to help with move ordering
2. Calculating the move value to help with move ordering.
3. Doing probable solves to make sure the selected move cuts off.

"Search Cost" is basically node count, so we need a node counter. In preparation for multithreaded, it can't be global.
So make a midgame class called Search. This should also mimic the node count cost in a full depth search, so the move sorting should be similar (I think).

Calculating the move value also requires some move sorting to run in a reasonable time.

Probable solves will require MPC and a Solver instance that runs in the same thread as the Search.

We'll implement 1 and 2 first, so no MPC for now.

Simplify Search
---------------
Combine search for move and search for score into one function so sorting needs only be implemented once.
new SearchTiming test:
    1980 ms elapsed. 8,628,215 flips / 6,485,173 evals. 0.31 us/eval

Add iid at depths > 4, at depth d-4:
    1045 ms elapsed. 4,601,409 flips / 3,364,334 evals. 0.31 us/eval

Add iid at depths > 2, at depth d-2:
    734 ms elapsed. 3,303,109 flips / 2,361,971 evals. 0.31 us/eval

iid at depths >2, at depth 1:
    777 ms elapsed. 3,425,900 flips / 2,486,709 evals. 0.31 us/eval

iid at depth >2, at depth 1 when depth = 3, depth=2 otherwise
    725 ms elapsed. 3,201,492 flips / 2,311,664 evals. 0.31 us/eval